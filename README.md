# ðŸŽ†ðŸŽ‰  End-to-End-NLP-Project-with-RNN ðŸŽ‰ðŸŽ†

This project aims to classify hate speech using a deep learning model. The dataset for this project was sourced from Kaggle and underwent significant preprocessing to ensure a balanced and clean training set.

### ðŸŽ‡ Project Overview ðŸŽ‡
In this project, I tackled the challenge of detecting hate speech using an LSTM-based model. The dataset contained inherent imbalance, so I combined two separate datasets into one during preprocessing to ensure more robust model performance.

### âœ¨ Key Features:
* **Model Architecture**: LSTM (Long Short-Term Memory) neural network for text classification.
* **Embedding Layer**: Used Keras' embedding layer to handle word representations.
* **Model Size**: The model consists of approximately 5,080,501 total parameters.
* **Data Preprocessing**:
   - Combined two datasets to address imbalance issues.
   - Applied text preprocessing steps such as tokenization, lowercasing, and removal of stopwords. 



# Project Tree Structure
``` bash

.
â”œâ”€â”€ END-TO-END-NLP-PROJECT-WITH-LSTM
â”œâ”€â”€ .circleci/
â”‚   â””â”€â”€ config.yml
â”œâ”€â”€ artifact/
â”‚   â”œâ”€â”€ 10_05_2024_03_23_14 (or time Stamp)/
â”‚   â”‚   â”œâ”€â”€ DataIngestionArtifacts/
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.zip
â”‚   â”‚   â”‚   â”œâ”€â”€ imbalanced_data.csv
â”‚   â”‚   â”‚   â””â”€â”€ raw_data.csv
â”‚   â”‚   â”œâ”€â”€ DataValidationArtifacts/
â”‚   â”‚   â”‚   â””â”€â”€ status.txt
â”‚   â”‚   â”œâ”€â”€ DataTransformationArtifacts/
â”‚   â”‚   â”‚   â””â”€â”€ final.csv
â”‚   â”‚   â”œâ”€â”€ ModelTrainerArtifacts/
â”‚   â”‚   â”‚   â”œâ”€â”€ model.h5
â”‚   â”‚   â”‚   â”œâ”€â”€ x_test.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ x_train.csv
â”‚   â”‚   â”‚   â””â”€â”€ y_test.csv        
â”‚   â”‚   â””â”€â”€ ModelEvaluationArtifacts    /
â”‚   â”‚       â””â”€â”€ best_model/
â”‚   â”‚           â””â”€â”€ model.h5
â”‚   â””â”€â”€ PredicModel /
â”‚       â””â”€â”€ model.h5  
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.zip
â”œâ”€â”€ Hate or src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ __pychache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”‚   â”œâ”€â”€ model_pusher.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”œâ”€â”€ configuration/
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ s3_syncer.py
â”‚   â”œâ”€â”€ constants/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ entity/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py
â”‚   â”‚   â””â”€â”€ config_entity.py
â”‚   â”œâ”€â”€ exception/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â””â”€â”€ __init__py
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ model.py
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ __pycache__/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ training_pipeline.py
â”‚       â””â”€â”€ prediction_pipeline.py
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ 10_05_2024_03_23_14.log/
â”‚       â””â”€â”€ 10_05_2024_03_23_14.log
â”œâ”€â”€ Notebook/
â”‚   â””â”€â”€ Hate_speech_experiment.ipynb
â”œâ”€â”€ s3_downloads/
â”‚   â””â”€â”€ dataset.zip
â”œâ”€â”€ app.py
â”œâ”€â”€ circleci_setup_template.sh
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ template.py

```



## How to run?
``` bash
conda create -n hate python=3.8 -y
```

``` bash
conda activate hate
```

``` bash
pip install -r requirements.txt
```

### Export the environment variable(gitbash)

``` bash
export AWS_ACCESS_KEY_ID="your access key"
```
``` bash
export AWS_SECRET_ACCESS_KEY="your secret access key"
```
``` bash
export AWS_DEFAULT_REGION="e.g, us-east-1"  
```



ðŸŽ†ðŸŽ‰ # Workflow ðŸŽ‰ðŸŽ†

After creating the project template:
 * ðŸ”¥ Update constants 
 * ðŸ”¥ Update Entity modules
 * ðŸ”¥ Update respective component
 * ðŸ”¥ Update pipeline


## ðŸŽ† Deployment ðŸŽ†

1. Setting up CircleCI ðŸŽ‰
2. Switching on self-hosted runner ðŸ’¥
3. Creating Project ðŸŽŠ
4. Configuring EC2 ðŸš€
5. Writing `config.yml` ðŸ“œ
6. Setting environment variables ðŸ”’



## Code Training & Prediction pipeline working properly, updating my circleCI CICD deployment in future.
